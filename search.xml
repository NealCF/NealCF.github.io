<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>在MAC上通过Hexo+Github Page搭建个人博客</title>
      <link href="/2020/07/03/hexo-githubpage-for-selfblog/"/>
      <url>/2020/07/03/hexo-githubpage-for-selfblog/</url>
      
        <content type="html"><![CDATA[<p>开篇提示，此文档为自己的部署过程，顾做一次搬运工文章搬运工，也是第一次写博客练手啦。</p><h2 id="环境描述"><a href="#环境描述" class="headerlink" title="环境描述"></a>环境描述</h2><p>OS：macOS Mojave 10.14.5<br>Repositories：<a href="https://github.com/" target="_blank" rel="noopener">https://github.com/</a><br>评论功能：<a href="https://livere.com/" target="_blank" rel="noopener">https://livere.com/</a><br>留言板功能：<a href="https://www.daocloud.io/" target="_blank" rel="noopener">https://www.daocloud.io/</a></p><p>参考文献：<a href="https://blog.csdn.net/weixin_41160054/article/details/89531921" target="_blank" rel="noopener">https://blog.csdn.net/weixin_41160054/article/details/89531921</a></p><p>​                   <a href="https://www.jianshu.com/p/921efd17b844" target="_blank" rel="noopener">https://www.jianshu.com/p/921efd17b844</a></p><p>​                   <a href="https://blinkfox.github.io/2018/09/28/qian-duan/hexo-bo-ke-zhu-ti-zhi-hexo-theme-matery-de-jie-shao/#toc-heading-1" target="_blank" rel="noopener">https://blinkfox.github.io/2018/09/28/qian-duan/hexo-bo-ke-zhu-ti-zhi-hexo-theme-matery-de-jie-shao/#toc-heading-1</a></p><h2 id="仓库准备"><a href="#仓库准备" class="headerlink" title="仓库准备"></a>仓库准备</h2><h3 id="Github仓库建立"><a href="#Github仓库建立" class="headerlink" title="Github仓库建立"></a>Github仓库建立</h3><p>登录<a href="https://github.com/后，点击右上角头像，点击“Your" target="_blank" rel="noopener">https://github.com/后，点击右上角头像，点击“Your</a> repositories”后进入个人github仓库。而后点击“New”创建新的仓库，因为我们要建网站，所以我们的「Repository name」应该和我们的github名字保持一致。同时仓库属性为public。设置完成后点击下方的“create repository”<br>例如：你的账户名字为NealCF，那么我们需要填写的是NealCF.github.io。同时，因为我自己的网站已经搭建好了，所以出现了下面的警告⚠️，不用在意。</p><img src="/2020/07/03/hexo-githubpage-for-selfblog/image-20200625142434759.png" class="" title="image-20200625142434759"><img src="/2020/07/03/hexo-githubpage-for-selfblog/image-20200625142448912.png" class="" title="image-20200625142448912"><img src="/2020/07/03/hexo-githubpage-for-selfblog/image-20200625142455009.png" class="" title="image-20200625142455009"><h3 id="配置github仓库免密"><a href="#配置github仓库免密" class="headerlink" title="配置github仓库免密"></a>配置github仓库免密</h3><p>生成新的SSH keys：</p><pre><code>$ ssh-keygen -t rsa -C &quot;你的邮箱地址&quot;Generating public/private rsa key pair.Enter file in which to save the key (/Users/your_user_directory/.ssh/id_rsa):&lt;回车&gt;Enter passphrase (empty for no passphrase):&lt;输入加密串&gt;&lt;如不想设置密码可直接回车表示为空&gt;Enter same passphrase again:&lt;再次输入加密串&gt;&lt;接着回车确认&gt;Your identification has been saved in /Users/你的名字/.ssh/id_rsa).Your public key has been saved in /Users/你的名字/.ssh/id_rsa.pub.The key fingerprint is:43:c5:5b:5f:b1:f1:50:43:ad:20:a6:92:6a:1f:9a:3a &quot;你的邮箱地址&quot; </code></pre><p>打开本地刚生成的.ssh/id_rsa.pub（若看不到，则需显示隐藏文件）,准确复制文件中所有内容。然后进入github主页，点击右上角头像进入settings，选择SSH and GPG keys，再点击New SSH Key。将内容复制进key，title可以为空。最后Add SSH key。<br>可以通过如下命令进行测试是否成功：</p><pre><code>$ ssh -T git@GitHub.com #全部复制，无需更改</code></pre><p>若出现以下提示，表示SSH key添加成功：</p><pre><code>The authenticity of host &#39;GitHub.com (207.97.227.239)&#39; can&#39;t be established.RSA key fingerprint is 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48.Are you sure you want to continue connecting (yes/no)?&lt;输入yes&gt;Hi 你的用户名! You&#39;ve successfully authenticated, but GitHub does not provide shell access.</code></pre><p>测试github pages是否创建成功：</p><pre><code>echo &quot;# 你的用户名.github.io&quot; &gt;&gt; README.mdgit init    git add README.mdgit commit -m &quot;first commit&quot;git remote add origin https://github.com/你的用户名/你的用户名.github.io.gitgit push -u origin master</code></pre><p>之后在浏览器中输入 【你的名字】.github.io ，如果成功出现页面，并且页面上是你刚输入的地址，那么github pages配置成功。</p><h2 id="Node-js安装"><a href="#Node-js安装" class="headerlink" title="Node.js安装"></a>Node.js安装</h2><h3 id="什么是Node-js"><a href="#什么是Node-js" class="headerlink" title="什么是Node.js"></a>什么是Node.js</h3><p>简单的说 Node.js 就是运行在服务端的 JavaScript。Node.js 是一个基于Chrome JavaScript 运行时建立的一个平台。Node.js是一个事件驱动I/O服务端JavaScript环境，基于Google的V8引擎，V8引擎执行Javascript的速度非常快，性能非常好。更多Node.js的基础教程参考：<a href="https://www.runoob.com/nodejs/nodejs-tutorial.html" target="_blank" rel="noopener">https://www.runoob.com/nodejs/nodejs-tutorial.html</a></p><h3 id="Node-js的组成"><a href="#Node-js的组成" class="headerlink" title="Node.js的组成"></a>Node.js的组成</h3><p>ECMAScript（语言基础，如：语法、数据类型结构以及一些内置对象）<br>OS（操作系统）<br>file（文件系统）<br>net（网络系统）<br>database（数据库）<br>注意：</p><p>ECMAScript （是js的标准，js是它的具体实现和扩展，他描述语言的语法和基本对象，如：语法、运算符、语句、继承机制、数据结构以及一些内置对象）<br>DOM（文档对象模型，描述处理网页内容的方法和接口，将整个文档document解析成dom树供用户使用js对文档进行处理）。<br>BOM（浏览器对象模型，描述可以和浏览器窗口交互的方法和接口「对象结构」，如：window对象，history，location，navigator等）</p><h3 id="Node-js安装-1"><a href="#Node-js安装-1" class="headerlink" title="Node.js安装"></a>Node.js安装</h3><blockquote><p>需要注意的是，在我们安装<code>node.js</code>的时候，也需要同时安装<code>npm</code>。而这是最容易出问题的地方。</p></blockquote><h4 id="什么是npm"><a href="#什么是npm" class="headerlink" title="什么是npm"></a>什么是npm</h4><p>npm的全称node package manager，是一个node包的管理工具。</p><p>npm（Node Package Manager）是Node.js下的主流套件管理程式。它在Node.js v0.6.x版本之后，内建于Node系统。通过npm可以协助开发者安装、卸载、删除、更新Node.js套件。因此安装Node.js的时候最好一起也安装npm!</p><h4 id="如何安装Node-js和npm"><a href="#如何安装Node-js和npm" class="headerlink" title="如何安装Node.js和npm"></a>如何安装Node.js和npm</h4><blockquote><p>使用一个node version manager来安装 <code>Node.js</code>和<code>npm</code>。</p></blockquote><p>第一步：安装nvm和确认是否成功</p><pre><code>curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.34.0/install.sh | bash</code></pre><p>然后，输入代码</p><pre><code>command -v nvm</code></pre><p>返回结果为nvm：</p><img src="/2020/07/03/hexo-githubpage-for-selfblog/image-20200625144450053.png" class="" title="image-20200625144450053"><p>若无此返回结果可重启terminal后尝试。</p><p>第二步：用nvm安装node</p><pre><code>nvm install node # &quot;node&quot; is an alias for the latest version</code></pre>{% asset_img image-20200625144654479.png image-20200625144654479 %}<h2 id="Hexo安装"><a href="#Hexo安装" class="headerlink" title="Hexo安装"></a>Hexo安装</h2><p>hexo的安装只需要使用npm进行安装，包的名字为hexo-cli</p><pre><code>npm install -g hexo-cli</code></pre><h2 id="网站配置"><a href="#网站配置" class="headerlink" title="网站配置"></a>网站配置</h2><p>安装 Hexo 完成后，我们可以在本地新建一个文件夹或采用下载仓库的方式进行完整初始化。</p><h3 id="下载仓库"><a href="#下载仓库" class="headerlink" title="下载仓库"></a>下载仓库</h3><p>规划好网站在本地的存放位置后，将github上的仓库clone下来，进行网站初始化：</p><p>备注：我规划的位置为/Users/{用户名}/Documents下。</p><pre><code>$ cd /Users/cjm/Documents/$ git clone https://github.com/yourGithubName/yourGithubName.github.io</code></pre><h3 id="清空本地仓库目录，进行网站初始化"><a href="#清空本地仓库目录，进行网站初始化" class="headerlink" title="清空本地仓库目录，进行网站初始化"></a>清空本地仓库目录，进行网站初始化</h3><blockquote><p>必须确认当前工作目录是否为本地仓库目录。或可采用mv进行目录重命名后新建原目录的方式</p></blockquote><pre><code>进入本地仓库目录：$ cd /Users/cjm/Documents/NealCF.github.io/确认目录结构：$ pwd/Users/cjm/Documents/NealCF.github.io确认目录中文件内容（包含隐藏文件）$ ls -al清空本地仓库内容$ rm -rf *</code></pre><h3 id="Hexo初始化"><a href="#Hexo初始化" class="headerlink" title="Hexo初始化"></a>Hexo初始化</h3><p>建立初始化方式如下：</p><pre><code>$ cd /Users/cjm/Documents/NealCF.github.io/$ hexo init ./$ hexo generate</code></pre><p>下面介绍几个常用的hexo命令(括号里面的命令为缩写形式，效果一样)：</p><ol><li>hexo generate(hexo g) #生成静态文件，会在当前目录下生成一个新的叫做public的文件夹</li><li>hexo new “postTitle” #新建博客文章</li><li>hexo new page “pageTitle” #新建1个页面</li><li>hexo server(hexo s) #启动本地web服务预览(加参数–debug,用于调试，如：hexo s –debug)</li><li>hexo deploy(hexo d) #部署播客到远端（比如Github,coding,heroku等平台）</li></ol><p>在命令行中输入<code>hexo s --debug</code>后，运行成功后，可以在浏览器中输入：<a href="http://localhost:4000看到自己新建的博客了。">http://localhost:4000看到自己新建的博客了。</a></p><h3 id="更改主题"><a href="#更改主题" class="headerlink" title="更改主题"></a>更改主题</h3><blockquote><p>在本地仓库的根目录下存在_config.yml，同时在theme下的每个主图目录内仍有_config.yml。根config.yml为全局配置，主题的config.yml为主题自定义配置。配置过程中注意区分。</p></blockquote><p>一般我们初始化博客的文件夹后，文件结构大概如下：</p><pre><code>$ lltotal 1352-rw-r--r--    1 builder34  staff    32B  4 14 01:34 README.md-rw-r--r--    1 builder34  staff   2.3K  6 25 10:40 _config.yml-rw-r--r--    1 builder34  staff    32K  6 26 15:50 db.json-rw-r--r--    1 builder34  staff   458K  6 26 15:56 debug.logdrwxr-xr-x  293 builder34  staff   9.2K  6 25 10:42 node_modules-rw-r--r--    1 builder34  staff   110K  6 22 23:59 package-lock.json-rw-r--r--    1 builder34  staff   564B  6 22 23:59 package.jsondrwxr-xr-x   14 builder34  staff   448B  6 25 10:40 publicdrwxr-xr-x    5 builder34  staff   160B  4 17 23:12 scaffoldsdrwxr-xr-x    3 builder34  staff    96B  6 25 10:57 sourcedrwxr-xr-x    6 builder34  staff   192B  6 25 11:33 themes</code></pre><p>themes文件夹是我们博客主题的存放地方，大家可以在<a href="https://hexo.io/themes/" target="_blank" rel="noopener">https://hexo.io/themes/</a>  上选择自己喜欢的主题，建议选择文档描述清楚的，可以减轻自己的配置测试的次数。我所使用的是：<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank" rel="noopener">hexo-theme-matery</a>。 </p><pre><code>$ cd themes/$ git clone https://github.com/blinkfox/hexo-theme-matery.git</code></pre><p>在Hexo配置文件（$your_blog_path/_config.yml）中把主题设置修改为hexo-theme-matery。</p><pre><code>修改 Hexo 根目录下的 _config.yml 的 theme 的值：theme: hexo-theme-matery</code></pre><p>_config.yml 文件的其它修改建议:<br>请修改 _config.yml 的 url 的值为你的网站主 URL（如：<a href="http://xxx.github.io）。" target="_blank" rel="noopener">http://xxx.github.io）。</a><br>建议修改两个 per_page 的分页条数值为 6 的倍数，如：12、18 等，这样文章列表在各个屏幕下都能较好的显示。<br>如果你是中文用户，则建议修改 language 的值为 zh-CN，timezone的值为 Asia/Shanghai。</p><p>具体配置文档为：<a href="https://blinkfox.github.io/2018/09/28/qian-duan/hexo-bo-ke-zhu-ti-zhi-hexo-theme-matery-de-jie-shao/#toc-heading-1" target="_blank" rel="noopener">https://blinkfox.github.io/2018/09/28/qian-duan/hexo-bo-ke-zhu-ti-zhi-hexo-theme-matery-de-jie-shao/#toc-heading-1</a></p><h3 id="Hexo部署到github"><a href="#Hexo部署到github" class="headerlink" title="Hexo部署到github"></a>Hexo部署到github</h3><p>安装hexo deployer 插件</p><pre><code>使用 hexo deploy 命名部署到github所需要的hexo插件$ npm install hexo-deployer-git --save</code></pre><p>配置根_config.yml的deloyment:</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># Deployment</span><span class="token comment" spellcheck="true">## Docs: https://hexo.io/docs/deployment.html</span>deploy:  type: <span class="token function">git</span>  repo: https://github.com/your_githubName/your_githubName.github.io.git</code></pre><p>生成静态页面并部署到远端github pages</p><pre class=" language-ruby"><code class="language-ruby"><span class="token comment" spellcheck="true">#删除静态文件,即 public 文件</span>$ hexo clean<span class="token comment" spellcheck="true">#生成静态文件,即 public 文件</span>$ hexo generate<span class="token comment" spellcheck="true">#部署到远程站点</span>$ hexo deploy<span class="token comment" spellcheck="true">#也可以使用组合命令(替代上面2条命令)：生成静态命令并部署到远程站点</span>$ hexo deploy <span class="token operator">-</span>g</code></pre><h2 id="设置博客域名"><a href="#设置博客域名" class="headerlink" title="设置博客域名"></a>设置博客域名</h2><p>进入自己博客的repository仓库，默认博客域名为<a href="https://your_githubName.github.io。" target="_blank" rel="noopener">https://your_githubName.github.io。</a> 可以通过类似如下的页面进行设置自定义域名：</p><img src="/2020/07/03/hexo-githubpage-for-selfblog/image-20200625152625436.png" class="" title="image-20200625152625436"><img src="/2020/07/03/hexo-githubpage-for-selfblog/image-20200625152629998.png" class="" title="image-20200625152629998"><p>所填的自定义域名是需要自己已经注册，并且如果勾选了 Enforce HTTPS 的话，你的域名是需要ssl证书。</p><h2 id="注意事项-自行判读是否配置"><a href="#注意事项-自行判读是否配置" class="headerlink" title="注意事项(自行判读是否配置)"></a>注意事项(自行判读是否配置)</h2><h3 id="上传README-md并防止被渲染成文章"><a href="#上传README-md并防止被渲染成文章" class="headerlink" title="上传README.md并防止被渲染成文章"></a>上传README.md并防止被渲染成文章</h3><pre><code>#在博客根目录下，新建或编辑你的README.md文件$ vim README.md$ mv README.md ./sources#修改_config.yml文件,设置不渲染的文件$ vim _config.ymlskip_render: README.md</code></pre><h3 id="自定义域名重置问题"><a href="#自定义域名重置问题" class="headerlink" title="自定义域名重置问题"></a>自定义域名重置问题</h3><p>每次<code>hexo deploy</code>后Github Pages自定义域名会被重置，需要在sources目录下新建CNAME文件(注意为全大写无后缀的文件哦),文件内容为你需要映射到的自定义域名：</p><pre><code>$ vim CNAMEblog.monbuilder.top$ mv CNAME ./sources</code></pre><h2 id="配合Hexo配置Typora"><a href="#配合Hexo配置Typora" class="headerlink" title="配合Hexo配置Typora"></a>配合Hexo配置Typora</h2><p>使用typora添加图片配置，参考<a href="https://wanglin0c.github.io/2020/06/25/blog_hexo/" target="_blank" rel="noopener">https://wanglin0c.github.io/2020/06/25/blog_hexo/</a></p><p>配置typora的图像设置部分，偏好设置&gt;图像，选择复制到指定路径，并勾选”优先使用相对路径”，这样在粘贴图片到文档上的时候，就会在文档所在目录创建一个同名的目录存放该文档上的图片，并且图片的路径显示为该文件夹的相对路径，如“blog_hexo/xxxxx.png”，此时typora就可以显示该相对路径的图片，如图：</p><img src="/2020/07/03/hexo-githubpage-for-selfblog/image-20200625153331989.png" class="" title="image-20200625153331989"><p>修改hexo配置，如我的项目myblog_web目录下的配置文件_config.yml, 修改post_asset_folder的值为true，即使用相对路径。</p><pre><code>post_asset_folder: true1</code></pre><p>本地安装插件， 执行命令<code>npm install hexo-image-link --save</code> 解决typora图片路径问题，本地预览的时候就可以看到图片了。</p>]]></content>
      
      
      <categories>
          
          <category> other </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mac </tag>
            
            <tag> Hexo </tag>
            
            <tag> Github Page </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CSS心跳说明及调整方式</title>
      <link href="/2020/07/03/css-xin-tiao-shuo-ming-ji-diao-zheng-fang-shi/"/>
      <url>/2020/07/03/css-xin-tiao-shuo-ming-ji-diao-zheng-fang-shi/</url>
      
        <content type="html"><![CDATA[<h2 id="CSS心跳说明"><a href="#CSS心跳说明" class="headerlink" title="CSS心跳说明"></a>CSS心跳说明</h2><p> CSS 服务通过多种心跳机制实时监控集群状态，提供脑裂保护等基础集群服务功能。 CSS 服务有2种心跳机制： 一种是通过私有网络的<code>Network Heartbeat</code>，另一种是通过Voting Disk的<code>Disk Heartbeat</code>.<br>这2种心跳都有最大延时，对于<code>Disk Heartbeat</code>， 这个延时叫作IOT (I/O Timeout);对于<code>Network Heartbeat</code>, 这个延时叫MC(Misscount)。 这2个参数都以秒为单位，缺省时IOT大于MC</p><h2 id="MC调整方式"><a href="#MC调整方式" class="headerlink" title="MC调整方式"></a>MC调整方式</h2><pre><code>su - grid#获取当前心跳值crsctl get css misscount#设置新的心跳值crsctl set css misscount    240</code></pre><h2 id="disktimeout调整方式"><a href="#disktimeout调整方式" class="headerlink" title="disktimeout调整方式"></a>disktimeout调整方式</h2><pre><code>su - grid#获取当前心跳值crsctl get css disktimeout#设置新的心跳值crsctl set css disktimeout  300</code></pre><h2 id="asm心跳时间间隔调整"><a href="#asm心跳时间间隔调整" class="headerlink" title="asm心跳时间间隔调整"></a>asm心跳时间间隔调整</h2><pre><code>在rac正常状态下 grid账号下执行：sqlplus / as sysasmalter system set &quot;_asm_hbeatiowait&quot;=120 scope=spfile sid=&#39;*&#39;;重启crs服务/u01/app/11.2.0/grid/bin./crsctl stop cluster -all./crsctl start cluster -all检查参数：show parameter  _asm_hbeatiowait;</code></pre>]]></content>
      
      
      <categories>
          
          <category> oracle </category>
          
      </categories>
      
      
        <tags>
            
            <tag> oracle </tag>
            
            <tag> rac </tag>
            
            <tag> css </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2020/06/25/hello-world/"/>
      <url>/2020/06/25/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre class=" language-bash"><code class="language-bash">$ hexo new <span class="token string">"My New Post"</span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre class=" language-bash"><code class="language-bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre class=" language-bash"><code class="language-bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre class=" language-bash"><code class="language-bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p><pre><code>---title: typora-vue-theme主题介绍date: 2018-06-25 09:25:00author: Nealimg: /source/images/xxx.jpgtop: truecover: truecoverImg: /images/1.jpgtoc: falsesummary: 这是你自定义的文章摘要内容，如果这个属性有值，文章卡片摘要就显示这段文字，否则程序会自动截取文章的部分内容作为摘要categories: Markdowntags:  - Typora  - Markdown---</code></pre><pre><code>---title: 磁盘无分区xfs_growfs扩展文件系统categories: 操作系统tags:   - xfs_growfs---</code></pre>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>磁盘无分区xfs_growfs扩展文件系统</title>
      <link href="/2020/04/22/ci-pan-wu-fen-qu-xfs-growfs-kuo-zhan-wen-jian-xi-tong/"/>
      <url>/2020/04/22/ci-pan-wu-fen-qu-xfs-growfs-kuo-zhan-wen-jian-xi-tong/</url>
      
        <content type="html"><![CDATA[<h2 id="清除分区信息"><a href="#清除分区信息" class="headerlink" title="清除分区信息"></a>清除分区信息</h2><pre><code>[root@disk-test ~]# umount /mnt[root@disk-test ~]# dd if=/dev/zero of=/dev/vdb bs=1M count=10001000+0 records in1000+0 records out1048576000 bytes (1.0 GB) copied, 15.9085 s, 65.9 MB/s[root@disk-test ~]# [root@disk-test ~]# [root@disk-test ~]# [root@disk-test ~]# lsblkNAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTsr0     11:0    1 1024M  0 rom  sr1     11:1    1  464K  0 rom  vda    253:0    0   40G  0 disk └─vda1 253:1    0   40G  0 part /vdb    253:16   0  110G  0 disk </code></pre><h2 id="格式化磁盘并挂载"><a href="#格式化磁盘并挂载" class="headerlink" title="格式化磁盘并挂载"></a>格式化磁盘并挂载</h2><pre><code>[root@disk-test ~]# mkfs.xfs /dev/vdbmeta-data=/dev/vdb               isize=512    agcount=4, agsize=7208960 blks         =                       sectsz=512   attr=2, projid32bit=1         =                       crc=1        finobt=0, sparse=0data     =                       bsize=4096   blocks=28835840, imaxpct=25         =                       sunit=0      swidth=0 blksnaming   =version 2              bsize=4096   ascii-ci=0 ftype=1log      =internal log           bsize=4096   blocks=14080, version=2         =                       sectsz=512   sunit=0 blks, lazy-count=1realtime =none                   extsz=4096   blocks=0, rtextents=0[root@disk-test ~]# [root@disk-test ~]# mount /dev/vdb /mnt </code></pre><h2 id="确认分区信息"><a href="#确认分区信息" class="headerlink" title="确认分区信息"></a>确认分区信息</h2><pre><code>[root@disk-test ~]# lsblkNAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTsr0     11:0    1 1024M  0 rom  sr1     11:1    1  464K  0 rom  vda    253:0    0   40G  0 disk └─vda1 253:1    0   40G  0 part /vdb    253:16   0  110G  0 disk /mnt[root@disk-test ~]# df -ThFilesystem     Type      Size  Used Avail Use% Mounted on/dev/vda1      ext4       40G  1.2G   37G   4% /devtmpfs       devtmpfs  873M     0  873M   0% /devtmpfs          tmpfs     883M     0  883M   0% /dev/shmtmpfs          tmpfs     883M   17M  866M   2% /runtmpfs          tmpfs     883M     0  883M   0% /sys/fs/cgrouptmpfs          tmpfs     177M     0  177M   0% /run/user/0/dev/vdb       xfs       110G   33M  110G   1% /mnt</code></pre><h2 id="后台扩容磁盘"><a href="#后台扩容磁盘" class="headerlink" title="后台扩容磁盘"></a>后台扩容磁盘</h2><pre><code>[root@disk-test ~]# lsblkNAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTsr0     11:0    1 1024M  0 rom  sr1     11:1    1  464K  0 rom  vda    253:0    0   40G  0 disk └─vda1 253:1    0   40G  0 part /vdb    253:16   0  120G  0 disk /mnt</code></pre><h2 id="确认文件系统没有变化"><a href="#确认文件系统没有变化" class="headerlink" title="确认文件系统没有变化"></a>确认文件系统没有变化</h2><pre><code>[root@disk-test ~]# df -ThFilesystem     Type      Size  Used Avail Use% Mounted on/dev/vda1      ext4       40G  1.2G   37G   4% /devtmpfs       devtmpfs  873M     0  873M   0% /devtmpfs          tmpfs     883M     0  883M   0% /dev/shmtmpfs          tmpfs     883M   17M  866M   2% /runtmpfs          tmpfs     883M     0  883M   0% /sys/fs/cgrouptmpfs          tmpfs     177M     0  177M   0% /run/user/0/dev/vdb       xfs       110G   33M  110G   1% /mnt</code></pre><h2 id="自增涨文件系统"><a href="#自增涨文件系统" class="headerlink" title="自增涨文件系统"></a>自增涨文件系统</h2><pre><code>[root@disk-test ~]# xfs_growfs /dev/vdbmeta-data=/dev/vdb               isize=512    agcount=4, agsize=7208960 blks         =                       sectsz=512   attr=2, projid32bit=1         =                       crc=1        finobt=0 spinodes=0data     =                       bsize=4096   blocks=28835840, imaxpct=25         =                       sunit=0      swidth=0 blksnaming   =version 2              bsize=4096   ascii-ci=0 ftype=1log      =internal               bsize=4096   blocks=14080, version=2         =                       sectsz=512   sunit=0 blks, lazy-count=1realtime =none                   extsz=4096   blocks=0, rtextents=0data blocks changed from 28835840 to 31457280</code></pre><h2 id="确认文件系统大小"><a href="#确认文件系统大小" class="headerlink" title="确认文件系统大小"></a>确认文件系统大小</h2><pre><code>[root@disk-test ~]# df -ThFilesystem     Type      Size  Used Avail Use% Mounted on/dev/vda1      ext4       40G  1.2G   37G   4% /devtmpfs       devtmpfs  873M     0  873M   0% /devtmpfs          tmpfs     883M     0  883M   0% /dev/shmtmpfs          tmpfs     883M   17M  866M   2% /runtmpfs          tmpfs     883M     0  883M   0% /sys/fs/cgrouptmpfs          tmpfs     177M     0  177M   0% /run/user/0/dev/vdb       xfs       120G   33M  120G   1% /mnt</code></pre><h2 id="写文件系统，确认没问题"><a href="#写文件系统，确认没问题" class="headerlink" title="写文件系统，确认没问题"></a>写文件系统，确认没问题</h2><pre><code>[root@disk-test ~]# cd /mnt/[root@disk-test mnt]# touch 1.txt</code></pre>]]></content>
      
      
      <categories>
          
          <category> 操作系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> xfs_growfs </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>记录一次磁盘超时CRS故障报告</title>
      <link href="/2018/07/03/ji-lu-yi-ci-ci-pan-chao-shi-crs-gu-zhang-bao-gao/"/>
      <url>/2018/07/03/ji-lu-yi-ci-ci-pan-chao-shi-crs-gu-zhang-bao-gao/</url>
      
        <content type="html"><![CDATA[<h2 id="环境描述"><a href="#环境描述" class="headerlink" title="环境描述"></a>环境描述</h2><p>首先：这是oracle11g 一个bug ！！！！！</p><p>OS：AIX7</p><p>ORACLE：11.2.0.4</p><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>早晨发现db集群数据库的2节点db2的crs服务相关进程异常宕掉，且该节点的asm中OCRVOTE磁盘组处于dismount状态，监听listener_scan1无法正常连接。运维人员重启了集群服务及数据库后恢复正常。</p><h2 id="日志分析"><a href="#日志分析" class="headerlink" title="日志分析"></a>日志分析</h2><p>日志内容较多，可以根据自身情况对号入座</p><h3 id="alert日志信息"><a href="#alert日志信息" class="headerlink" title="alert日志信息"></a>alert日志信息</h3><h4 id="节点1"><a href="#节点1" class="headerlink" title="节点1"></a>节点1</h4><p>db1 数据库 alert日志</p><pre><code>Wed Apr 17 03:28:41 2019Archived Log entry 70662 added for thread 1 sequence 45676 ID 0x69424941 dest 1:Wed Apr 17 03:39:59 2019ALTER SYSTEM SET service_names=&#39;SYS$SYS.KUPC$S_1_20190417031059.HISDB&#39; SCOPE=MEMORY SID=&#39;hisdb1&#39;;ALTER SYSTEM SET service_names=&#39;hisdb&#39; SCOPE=MEMORY SID=&#39;hisdb1&#39;;Wed Apr 17 03:40:04 2019ALTER SYSTEM SET service_names=&#39;SYS$SYS.KUPC$C_1_20190417034003.HISDB&#39; SCOPE=MEMORY SID=&#39;hisdb1&#39;;ALTER SYSTEM SET service_names=&#39;SYS$SYS.KUPC$C_1_20190417034003.HISDB&#39;,&#39;SYS$SYS.KUPC$S_1_20190417034003.HISDB&#39; SCOPE=MEMORY SID=&#39;hisdb1&#39;;Wed Apr 17 03:40:04 2019DM00 started with pid=319, OS id=34407144, job CLINIC_EMR.SYS_EXPORT_SCHEMA_01Wed Apr 17 03:40:06 2019DW00 started with pid=376, OS id=38667000, wid=1, job CLINIC_EMR.SYS_EXPORT_SCHEMA_01Wed Apr 17 03:40:50 2019Thread 1 advanced to log sequence 45678 (LGWR switch)  Current log# 5 seq# 45678 mem# 0: +REDO/hisdb/onlinelog/group_5.256.853305003  Current log# 5 seq# 45678 mem# 1: +REDO/hisdb/onlinelog/group_5.257.853305003  Current log# 5 seq# 45678 mem# 2: +DATA/hisdb/onlinelog/group_5.273.853305005Wed Apr 17 03:40:50 2019Archived Log entry 70665 added for thread 1 sequence 45677 ID 0x69424941 dest 1:…………此次省略重复信息……………….Wed Apr 17 04:28:04 2019Thread 1 advanced to log sequence 45679 (LGWR switch)  Current log# 7 seq# 45679 mem# 0: +REDO/hisdb/onlinelog/group_7.260.853305027  Current log# 7 seq# 45679 mem# 1: +REDO/hisdb/onlinelog/group_7.261.853305029  Current log# 7 seq# 45679 mem# 2: +DATA/hisdb/onlinelog/group_7.275.853305029Wed Apr 17 04:28:05 2019Archived Log entry 70666 added for thread 1 sequence 45678 ID 0x69424941 dest 1:…………此次省略正常输出……………….Wed Apr 17 07:36:02 2019Thread 1 advanced to log sequence 45680 (LGWR switch)  Current log# 8 seq# 45680 mem# 0: +REDO/hisdb/onlinelog/group_8.262.853305031  Current log# 8 seq# 45680 mem# 1: +REDO/hisdb/onlinelog/group_8.263.853305031  Current log# 8 seq# 45680 mem# 2: +DATA/hisdb/onlinelog/group_8.276.853305031Wed Apr 17 07:36:03 2019Archived Log entry 70667 added for thread 1 sequence 45679 ID 0x69424941 dest 1:Wed Apr 17 07:40:31 2019</code></pre><p>db1 asm alert日志</p><pre><code>Wed Apr 17 03:40:26 2019 Received dirty detach msg from inst 2 for dom 2Wed Apr 17 03:40:26 2019List of instances: 1 2Dirty detach reconfiguration started (new ddet inc 1, cluster inc 12) Global Resource Directory partially frozen for dirty detach* dirty detach - domain 2 invalid = TRUE  28 GCS resources traversed, 0 cancelledDirty Detach Reconfiguration completeWed Apr 17 03:40:26 2019NOTE: SMON starting instance recovery for group OCRVOTE domain 2 (mounted)NOTE: F1X0 found on disk 0 au 2 fcn 0.0NOTE: F1X0 found on disk 1 au 2 fcn 0.0NOTE: F1X0 found on disk 2 au 2 fcn 0.0NOTE: starting recovery of thread=1 ckpt=25.110 group=2 (OCRVOTE)NOTE: SMON waiting for thread 1 recovery enqueueNOTE: SMON about to begin recovery lock claims for diskgroup 2 (OCRVOTE)Wed Apr 17 03:40:26 2019NOTE: PST enabling heartbeating (grp 2)NOTE: SMON successfully validated lock domain 2NOTE: advancing ckpt for group 2 (OCRVOTE) thread=1 ckpt=25.110NOTE: SMON did instance recovery for group OCRVOTE domain 2</code></pre><h4 id="节点2"><a href="#节点2" class="headerlink" title="节点2"></a>节点2</h4><p>db2 数据库 alert 日志无异常输出，发现其实2节点的数据库状态是正常的。日志正常切换</p><p>db2 asm alert 日志:</p><p>通过分析alert_+ASM2.log日志， 发现OCRVOTE在Wed Apr 17 03:40:03 2019已经被dismount，具体如下：</p><pre><code>Wed Apr 17 03:40:03 2019WARNING: dirty detached from domain 2NOTE: cache dismounted group 2/0x8C01ED8D (OCRVOTE) SQL&gt; alter diskgroup OCRVOTE dismount force /* ASM SERVER:2348936589 */ Wed Apr 17 03:40:33 2019Errors in file /u01/oragrid/grid/diag/asm/+asm/+ASM2/trace/+ASM2_ora_2622396.trc:ORA-15078: ASM diskgroup was forcibly dismounted…………此次省略重复信息……………….WARNING: requested mirror side 1 of virtual extent 5 logical extent 0 offset 704512 is not allocated; I/O request failedWARNING: requested mirror side 2 of virtual extent 5 logical extent 1 offset 704512 is not allocated; I/O request failedErrors in file /u01/oragrid/grid/diag/asm/+asm/+ASM2/trace/+ASM2_ora_2622396.trc:ORA-15078: ASM diskgroup was forcibly dismountedORA-15078: ASM diskgroup was forcibly dismountedWed Apr 17 05:26:26 2019SQL&gt; alter diskgroup OCRVOTE check /* proxy */ ORA-15032: not all alterations performedORA-15001: diskgroup &quot;OCRVOTE&quot; does not exist or is not mountedERROR: alter diskgroup OCRVOTE check /* proxy */Wed Apr 17 05:26:52 2019NOTE: client exited [2360238]Wed Apr 17 05:26:53 2019NOTE: [crsd.bin@hisdbb (TNS V1-V3) 8257820] opening OCR file…………此次省略重复信息……………….通过该dismount的/* ASM SERVER:2348936589 */部分，可以知道该操作为asm自己完成，而非手工完成。我们继续向上查找CRS_DG磁盘组被dismount的原因。Wed Apr 17 03:40:02 2019WARNING: Waited 15 secs for write IO to PST disk 0 in group 2.WARNING: Waited 15 secs for write IO to PST disk 1 in group 2.WARNING: Waited 15 secs for write IO to PST disk 2 in group 2.WARNING: Waited 15 secs for write IO to PST disk 0 in group 2.WARNING: Waited 15 secs for write IO to PST disk 1 in group 2.WARNING: Waited 15 secs for write IO to PST disk 2 in group 2.这里看到的group 2就是OCRVOTE磁盘组，可以看到这里出现了对PST进行IO操作超时的warming。 PST是asm磁盘组状态的一种心跳检测机制，当对磁盘组PST的IO操作超过_asm_hbeatiowait仍不能完成，则会将该磁盘组dismount， 以保护数据一致性。_asm_hbeatiowait的默认值为15s，也就是上述告警中OCRVOTE磁盘组的超时时间。 （该特性只针对normal及high冗余的磁盘组生效，对于external冗余的磁盘组不会产生影响。DATA磁盘组为external冗余， 所以虽然PST IO超时超过51s，但未受到影响）。 OCRVOTE为normal冗余，所以由于该特性导致磁盘组被dismount。 由于该磁盘组只用于存储OCR和VOTE的相关信息， 数据库相关文件都在DATA及FRA磁盘组中， 所以尽管Wed Apr 17 03:40:03 2019 OCRVOTE磁盘组就已经被dismount但却并未影响数据库的正常读写。接下来继续来分析集群crs相关进程宕掉的原因：4.2 crsd日志2019-04-17 05:26:53.298: [ CRSMAIN][1] CRS Daemon Starting2019-04-17 05:26:53.299: [    CRSD][1] Logging level for Module: allcomp  02019-04-17 05:26:53.299: [    CRSD][1] Logging level for Module: default  02019-04-17 05:26:53.299: [    CRSD][1] Logging level for Module: COMMCRS  02019-04-17 05:26:53.299: [    CRSD][1] Logging level for Module: COMMNS  02019-04-17 05:26:53.299: [    CRSD][1] Logging level for Module: CSSCLNT  0…………此次省略部分信息……………….2019-04-17 05:26:53.302: [ CRSMAIN][1] Checking the OCR device2019-04-17 05:26:53.302: [ CRSMAIN][1] Sync-up with OCR2019-04-17 05:26:53.302: [ CRSMAIN][1] Connecting to the CSS Daemon2019-04-17 05:26:53.302: [ CRSMAIN][1] Getting local node number2019-04-17 05:26:53.303: [ CRSMAIN][1] Initializing OCR[   CLWAL][1]clsw_Initialize: OLR initlevel [70000]2019-04-17 05:26:53.744: [  OCRASM][1]proprasmo: Error in open/create file in dg [OCRVOTE][  OCRASM][1]SLOS : SLOS: cat=8, opn=kgfoOpen01, dep=15056, loc=kgfokge2019-04-17 05:26:53.744: [  OCRASM][1]ASM Error Stack : 2019-04-17 05:26:53.830: [  OCRASM][1]proprasmo: kgfoCheckMount returned [6]2019-04-17 05:26:53.830: [  OCRASM][1]proprasmo: The ASM disk group OCRVOTE is not found or not mounted2019-04-17 05:26:53.831: [  OCRRAW][1]proprioo: Failed to open [+OCRVOTE]. Returned proprasmo() with [26]. Marking location as UNAVAILABLE.2019-04-17 05:26:53.831: [  OCRRAW][1]proprioo: No OCR/OLR devices are usable2019-04-17 05:26:53.831: [  OCRASM][1]proprasmcl: asmhandle is NULL2019-04-17 05:26:53.832: [    GIPC][1] gipcCheckInitialization: possible incompatible non-threaded init from [prom.c : 690], original from [clsss.c : 5343]2019-04-17 05:26:53.855: [ default][1]clsvactversion:4: Retrieving Active Version from local storage.2019-04-17 05:26:53.874: [  OCRRAW][1]proprrepauto: The local OCR configuration matches with the configuration published by OCR Cache Writer. No repair required.2019-04-17 05:26:53.875: [  OCRRAW][1]proprinit: Could not open raw device 2019-04-17 05:26:53.875: [  OCRASM][1]proprasmcl: asmhandle is NULL2019-04-17 05:26:53.877: [  OCRAPI][1]a_init:16!: Backend init unsuccessful : [26]2019-04-17 05:26:53.878: [  CRSOCR][1] OCR context init failure.  Error: PROC-26: Error while accessing the physical storage2019-04-17 05:26:53.878: [    CRSD][1] Created alert : (:CRSD00111:) :  Could not init OCR, error: PROC-26: Error while accessing the physical storage2019-04-17 05:26:53.878: [    CRSD][1][PANIC] CRSD exiting: Could not init OCR, code: 262019-04-17 05:26:53.878: [    CRSD][1] Done.2019-04-17 05:26:54.576: [ CRSMAIN][1] First attempt: init CSS context succeeded.[  clsdmt][515]Listening to (ADDRESS=(PROTOCOL=ipc)(KEY=hisdbbDBG_CRSD))2019-04-17 05:26:54.611: [  clsdmt][515]PID for the Process [42402622], connkey 1 2019-04-17 05:26:54.612: [  clsdmt][515]Creating PID [42402622] file for home /u01/oragrid/11.2.0/grid host hisdbb bin crs to /u01/oragrid/11.2.0/grid/crs/init/2019-04-17 05:26:54.612: [  clsdmt][515]Writing PID [42402622] to the file [/u01/oragrid/11.2.0/grid/crs/init/hisdbb.pid] 2019-04-17 05:26:55.376: [ CRSMAIN][515] Policy Engine is not initialized yet!</code></pre><h3 id="trc日志信息"><a href="#trc日志信息" class="headerlink" title="trc日志信息"></a>trc日志信息</h3><h4 id=""><a href="#" class="headerlink" title=""></a></h4><pre><code>+ASM2_ora_2622396.trc日志内容# cat /u01/oragrid/grid/diag/asm/+asm/+ASM2/trace/+ASM2_ora_2622396.trcTrace file /u01/oragrid/grid/diag/asm/+asm/+ASM2/trace/+ASM2_ora_2622396.trcOracle Database 11g Enterprise Edition Release 11.2.0.4.0 - 64bit ProductionWith the Real Application Clusters and Automatic Storage Management optionsORACLE_HOME = /u01/oragrid/11.2.0/gridSystem name:    AIXNode name:      hisdbbRelease:        1Version:        7Machine:        00F914484C00Instance name: +ASM2Redo thread mounted by this instance: 0 &lt;none&gt;Oracle process number: 24Unix process pid: 2622396, image: oracle@hisdbb (TNS V1-V3)*** 2019-04-17 03:40:08.584*** SESSION ID:(769.3) 2019-04-17 03:40:08.584*** CLIENT ID:() 2019-04-17 03:40:08.584*** SERVICE NAME:() 2019-04-17 03:40:08.584*** MODULE NAME:(crsd.bin@hisdbb (TNS V1-V3)) 2019-04-17 03:40:08.584*** ACTION NAME:() 2019-04-17 03:40:08.584Received ORADEBUG command (#1) &#39;CLEANUP_KFK_FD&#39; from process &#39;Unix process pid: 42270836, image: &lt;none&gt;&#39;*** 2019-04-17 03:40:08.597Finished processing ORADEBUG command (#1) &#39;CLEANUP_KFK_FD&#39;*** 2019-04-17 03:40:23.525Received ORADEBUG command (#2) &#39;CLEANUP_KFK_FD&#39; from process &#39;Unix process pid: 42270836, image: &lt;none&gt;&#39;*** 2019-04-17 03:40:23.525Finished processing ORADEBUG command (#2) &#39;CLEANUP_KFK_FD&#39;*** 2019-04-17 03:40:33.260WARNING:failed xlate 1 ORA-15078: ASM diskgroup was forcibly dismounted…………此次省略部分信息……………….*** 2019-04-17 05:26:26.036WARNING:failed xlate 1 ORA-15078: ASM diskgroup was forcibly dismountedksfdrfms:Mirror Read file=+OCRVOTE.255.4294967295 fob=700010039003d68 bufp=110751000 blkno=1452 nbytes=4096WARNING:failed xlate 1 WARNING: requested mirror side 1 of virtual extent 5 logical extent 0 offset 704512 is not allocated; I/O request failedksfdrfms:Read failed from mirror side=1 logical extent number=0 dskno=65535WARNING:failed xlate 1 WARNING: requested mirror side 2 of virtual extent 5 logical extent 1 offset 704512 is not allocated; I/O request failedksfdrfms:Read failed from mirror side=2 logical extent number=1 dskno=65535ORA-15078: ASM diskgroup was forcibly dismountedORA-15078: ASM diskgroup was forcibly dismounted</code></pre><pre><code>+ASM1_gmon_27098.trc日志内容：Trace file /u01/oragrid/grid/diag/asm/+asm/+ASM2/trace/+ASM2_gmon_4653254.trc…………此次省略部分信息……………….*** 2019-04-17 03:40:02.533WARNING: Waited 15 secs for write IO to PST disk 1 in group 2.WARNING: Waited 15 secs for write IO to PST disk 2 in group 2.NOTE: Set to be offline flag for disk OCRVOTE_0000 only locally: flag 0x3211NOTE: Set to be offline flag for disk OCRVOTE_0001 only locally: flag 0x3211NOTE: Set to be offline flag for disk OCRVOTE_0002 only locally: flag 0x3211WARNING: Waited 15 secs for write IO to PST disk 0 in group 2.WARNING: Waited 15 secs for write IO to PST disk 1 in group 2.WARNING: Waited 15 secs for write IO to PST disk 2 in group 2.----- Abridged Call Stack Trace -----ksedsts()+240&lt;-kfdpGc_doTobeoflnAsync()+44&lt;-kfdpGc_checkTobeofln()+632&lt;-kfdpGc_timeout()+20&lt;-kfdp_timeoutBg()+1156&lt;-ksbcti()+5928&lt;-ksbabs()+796&lt;-ksbrdp()+2216&lt;-opirip()+1620&lt;-opidrv()+608&lt;-sou2o()+136&lt;-opimai_real()+188&lt;-ssthrdmain()+276&lt;-main()+204&lt;-__start()+112----- End of Abridged Call Stack Trace -----GMON checking disk modes for group 2 at 10 for pid 28, osid 24379752  dsk = 0/0xdbf11d86, mask = 0x7e, op = clear  dsk = 1/0xdbf11d87, mask = 0x7e, op = clear  dsk = 2/0xdbf11d88, mask = 0x7e, op = clearPOST (justCheck) res = 0 =============== PST ==================== grpNum:    2 state:     2 callCnt:   10 (lockvalue) valid=1 ver=1.1 ndisks=3 flags=0x0 from inst=1 (I am 2) last=2(lockvalue) dsks: 0 1 2--------------- HDR -------------------- next:      2 last:      2 pst count:      255 (invalid pst count) incarn:        1 dta size:      0 version:      1 ASM version:      186646528 = 11.2.0.0.0contenttype:      1partnering pattern:      [ ]--------------- LOC MAP ---------------- --------------- DTA -------------------- --------------- HBEAT ------------------ kfdpHbeat_dump: state=1, inst=2, ts=33083849.1420414976,     rnd=454597524.4167353850.218858772.3095438849.kfk io-queue:    0kfdpHbeatCB_dump: at 1108307f8 with ts=04/17/2019 03:39:47 iop=110830808, grp=2, disk=0/3690012038, isWrite=1 Hbeat #95 state=4 iostate=3kfdpHbeatCB_dump: at 110830630 with ts=04/17/2019 03:39:47 iop=110830640, grp=2, disk=1/3690012039, isWrite=1 Hbeat #95 state=4 iostate=3kfdpHbeatCB_dump: at 110830468 with ts=04/17/2019 03:39:47 iop=110830478, grp=2, disk=2/3690012040, isWrite=1 Hbeat #95 state=4 iostate=3GMON updating disk modes for group 2 at 11 for pid 28, osid 24379752  dsk = 0/0xdbf11d86, mask = 0x6a, op = clear  dsk = 1/0xdbf11d87, mask = 0x6a, op = clear  dsk = 2/0xdbf11d88, mask = 0x6a, op = clearPOST res = 0 =============== PST ==================== grpNum:    2 state:     2 callCnt:   11 (lockvalue) valid=1 ver=1.1 ndisks=3 flags=0x0 from inst=1 (I am 2) last=2(lockvalue) dsks: 0 1 2--------------- HDR -------------------- next:      2 last:      2 pst count:      255 (invalid pst count) incarn:        1 dta size:      0 version:      1 ASM version:      186646528 = 11.2.0.0.0contenttype:      1partnering pattern:      [ ]--------------- LOC MAP ---------------- --------------- DTA -------------------- --------------- HBEAT ------------------ kfdpHbeat_dump: state=1, inst=2, ts=33083849.1420414976,     rnd=454597524.4167353850.218858772.3095438849.kfk io-queue:    0kfdpHbeatCB_dump: at 1108307f8 with ts=04/17/2019 03:39:47 iop=110830808, grp=2, disk=0/3690012038, isWrite=1 Hbeat #95 state=4 iostate=3kfdpHbeatCB_dump: at 110830630 with ts=04/17/2019 03:39:47 iop=110830640, grp=2, disk=1/3690012039, isWrite=1 Hbeat #95 state=4 iostate=3kfdpHbeatCB_dump: at 110830468 with ts=04/17/2019 03:39:47 iop=110830478, grp=2, disk=2/3690012040, isWrite=1 Hbeat #95 state=4 iostate=3NOTE: kfdp_updateInt: forceDismount grp 2NOTE: GMON: failed to update modes: triggering force dismount of group 22019-04-17 03:40:02.614046 : kfdpHbeatblk_transfer: Found pending Hbeat I/O in grp=2 @    HBeatCblk=0x1108307f8 iop=0x110830808 iostate=3.kfdpHbeatCB_dump: at 1108307f8 with ts=04/17/2019 03:39:47 iop=110830808, grp=2, disk=0/3690012038, isWrite=1 Hbeat #95 state=4 iostate=32019-04-17 03:40:02.614121 : kfdpHbeatblk_transfer: Found pending Hbeat I/O in grp=2 @    HBeatCblk=0x110830630 iop=0x110830640 iostate=3.kfdpHbeatCB_dump: at 110830630 with ts=04/17/2019 03:39:47 iop=110830640, grp=2, disk=1/3690012039, isWrite=1 Hbeat #95 state=4 iostate=32019-04-17 03:40:02.614146 : kfdpHbeatblk_transfer: Found pending Hbeat I/O in grp=2 @    HBeatCblk=0x110830468 iop=0x110830478 iostate=3.kfdpHbeatCB_dump: at 110830468 with ts=04/17/2019 03:39:47 iop=110830478, grp=2, disk=2/3690012040, isWrite=1 Hbeat #95 state=4 iostate=3----- Abridged Call Stack Trace -----ksedsts()+240&lt;-kfdpHbeatblk_transfer()+904&lt;-kfdp_forceDismountAsyncGmon()+576&lt;-kfdp_updateInt()+1404&lt;-kfdp_updateDskBg()+908&lt;-ksbabs()+2800&lt;-ksbrdp()+2216&lt;-opirip()+1620&lt;-opidrv()+608&lt;-sou2o()+136&lt;-opimai_real()+188&lt;-ssthrdmain()+276&lt;-main()+204&lt;-__start()+112----- End of Abridged Call Stack Trace -----*** 2019-04-17 03:40:03.134GMON dismounting group 2 at 12 for pid 32, osid 19661688NOTE: kfdp_doDismount: dismount grp 2*** 2019-04-17 03:40:05.585NOTE: kfdpUtil_freeSlMsg: ksvtst for grp: 2348936589 KSV status 0x10*** 2019-04-17 03:40:35.978NOTE: kfdpUtil_freeSlMsg: ksvtst for grp: 2348936589 KSV status 0x10InvalLck (group 1) force released *** 2019-04-17 07:50:38.365InvalLck (group 1) re-acquired in S InvalLck (group 3) force released InvalLck (group 3) re-acquired in S</code></pre><h3 id="oraagent-grid日志"><a href="#oraagent-grid日志" class="headerlink" title="oraagent_grid日志"></a>oraagent_grid日志</h3><pre><code>2019-04-17 05:26:52.185: [ CRSCOMM][772] IpcC: IPC client connection 7b to member 0 has been removed2019-04-17 05:26:52.204: [CLSFRAME][772] Removing IPC Member:{Relative|Node:0|Process:0|Type:1}2019-04-17 05:26:52.204: [CLSFRAME][772] Disconnected from CRSD:hisdbb process: {Relative|Node:0|Process:0|Type:1}2019-04-17 05:26:52.211: [   AGENT][2057]{0:1:7} {0:1:7} Created alert : (:CRSAGF00117:) :  Disconnected from server, Agent is shutting down.2019-04-17 05:26:52.211: [    AGFW][2057]{0:1:7} Agent is exiting with exit code: 1</code></pre><h3 id="listener-scan相关日志"><a href="#listener-scan相关日志" class="headerlink" title="listener_scan相关日志"></a>listener_scan相关日志</h3><pre><code>节点2 listener_scan1日志:No longer listening on: (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=172.17.100.5)(PORT=1521)))17-APR-2019 05:26:52 * service_died * LsnrAgt * 12537节点1 listenr_scan1日志上一次集群重启后此资源一直在节点2，故无日志输出。</code></pre><h2 id="分析过程"><a href="#分析过程" class="headerlink" title="分析过程"></a>分析过程</h2><p>可以看到在OCRVOTE磁盘组dismount之后，集群进行了对于OCR所在磁盘组的header check， 需要对OCRVOTE磁盘组进行IO操作， 然而OCRVOTE已经dismount， 无法进行操作， 使得header check失败， 导致了crs进程宕掉。之后集群多次尝试重启crs进程都因为无法访问ocr所在磁盘组而失败， 达到最大尝试次数后不再尝试， crs进程彻底挂掉。这里会产生一个疑问，为什么crsd挂掉，但是ora.cssd没有OFFLINE（通过crsctl stat res -t -init可以确认ora.cssd没有挂掉，数据库实例还正常运行，节点并没有被踢出去），原因在于OCRVOTE对应的磁盘可能只是短暂的不可访问， cssd进程是直接访问OCRVOTE对应的3个ASM磁盘，并不依赖于CRS_DG磁盘组是mount状态，并且Clusterware默认的磁盘心跳超时时间为200秒，所以cssd进程没有出现问题。Cssd进程的正常运行，保证了集群节点间通讯可以正常完成， 该节点不会被整个集群踢掉重启，这也是为什么crs服务已经宕掉而数据库一直未受到影响的原因。</p><h2 id="过程梳理"><a href="#过程梳理" class="headerlink" title="过程梳理"></a>过程梳理</h2><p>故障过程：</p><p>Wed Apr 17 03:40:02 2019时OCRVOTE磁盘组的PST无法进行IO操作超过15s，Wed Apr 17 03:40:03 2019 ASM实例强制dismount OCRVOTE磁盘组，Wed Apr 17 05:26:26 2019 OCR Device Header Check Fail，Wed Apr 17 05:26:52 2019 CRS服务相关进程宕掉，此刻节点2 crsd offline。</p><p>恢复过程：</p><p>17-APR-2019 05:26:52 业务发现故障，Wed Apr 17 07:35:40 2019重启了hisdb2节点，Wed Apr 17 07:41:37 2019开始重启hisdb1节点集群服务，Wed Apr 17 07:51:43 2019开始重新启动hisdb1集群服务，Wed Apr 17 08:01:43 2019开始重新启动hisdb2集群服务，OCRVOTE磁盘组及crs服务状态恢复正常</p><h2 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h2><p>首先：这是oracle11g 一个bug ！！！！！</p><p>其次经查看集群相关日志可以确定，由于存储磁盘出现IO问题（或光线闪断、或IO延迟），导致集群CRS异常宕机。但是，比较奇怪的是，虽然CSR掉线了，ASM实例和DB实例却好好的，还可以正常使用。查询oracle support发现一篇文章1581864.1 提到ASM CRS仲裁盘访问超时与隐藏参数_asm_hbeatiowait有关系，而ASM的隐藏参数_asm_hbeatiowait由于操作系统多路径Multipath配置的polling_interval有关，具体的故障原因是操作系统盘的判断访问超时远大于数据库ASM仲裁盘访问超时，导致ORACLE RAC判定ASM中仲裁盘无法访问从而将仲裁盘强制Offline。解决的思路是：首先，确定操作系统polling_interval参数与数据库ASM隐藏参数值_asm_hbeatiowait，将_asm_hbeatiowait的值调整到比polling_interval值大即可。</p><h2 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h2><h3 id="临时处理办法"><a href="#临时处理办法" class="headerlink" title="临时处理办法"></a>临时处理办法</h3><pre><code>step1.mount 问题ASM盘su - gridsqlplus / as sysasmSQL&gt; alter diskgroup OCRVDISK mount;Diskgroup altered.step2.恢复服务cd /u01/app/11.2.0/grid/bin #./crsctl start crs[13:54:28]CRS-4640: Oracle High Availability Services is already active[13:54:28]CRS-4000: Command Start failed, or completed with errors.使用该方法拉起集群./crsctl start res ora.crsd -init检查#./crsctl check crs#./crsctl check cluster -all#./crs_stat -t</code></pre><h3 id="永久解决办法"><a href="#永久解决办法" class="headerlink" title="永久解决办法"></a>永久解决办法</h3><ol><li>查看数据库RAC ASM的_asm_hbeatiowait值（默认是15秒）：</li></ol><pre><code>SQL&gt; SELECT   ksppinm, ksppstvl, ksppdesc   FROM   x$ksppi x, x$ksppcv y  WHERE   x.indx = y.indx AND  ksppinm = &#39;_asm_hbeatiowait&#39;;KSPPINM     KSPPSTVL KSPPDESC-------------------- ---------- ------------------------------------------------------------_asm_hbeatiowait     15 number of secs to wait for PST Async Hbeat IO returnSQL&gt; </code></pre><ol start="2"><li>查看操作存储盘访问超时时间（默认是30秒）</li></ol><pre><code># cat /sys/block/sdb/device/timeout 30[root@rac1 ~]# cat /etc/redhat-release Red Hat Enterprise Linux Server release 6.8 (Santiago)[root@rac1 ~]# </code></pre><ol start="3"><li>将_asm_hbeatiowait 的值调整为45秒（该参数是静态参数，需要重启集群）</li></ol><pre><code>SQL&gt; alter system set &quot;_asm_hbeatiowait&quot;=120 scope=spfile sid=&#39;*&#39;;System altered.</code></pre><p>4、重启集群并重启服务器</p><h2 id="补充：官方解决建议"><a href="#补充：官方解决建议" class="headerlink" title="补充：官方解决建议"></a>补充：官方解决建议</h2><p>SOLUTION</p><p>1] Check with OS and Storage admin that there is disk unresponsiveness.</p><p>2] Possibly keep the disk responsiveness to below 15 seconds. </p><p>This will depend on various factors like</p><p>+ Operating System</p><p>+ Presence of Multipath ( and Multipath Type )</p><p>+ Any kernel parameter</p><p>So you need to find out, what is the ‘maximum’ possible disk unresponsiveness for your set up.For example, on AIX rw_timeout setting affects this and defaults to 30 seconds.</p><p>Another example is Linux with native multipathing. In such set up, number of physical paths and polling_interval value in multipath.conf file, will dictate this maximum disk unresponsiveness.</p><p>So for your set up ( combination of OS / multipath / storage ), you need to find out this.</p><p>3] If you can not keep the disk unresponsiveness to below 15 seconds, then the below parameter can be set in the ASM instance ( on all the Nodes of RAC ):</p><p>  _asm_hbeatiowait</p><p>As per internal bug 17274537 , based on internal testing the value should be increased to 120 secs, the same will be fixed in 12.2</p><p>Run below in asm instance to set desired value for _asm_hbeatiowait</p><p> alter system set “_asm_hbeatiowait”=<value> scope=spfile sid=’*’;</p><p>And then restart asm instance / crs, to take new parameter value in effect.</p>]]></content>
      
      
      <categories>
          
          <category> oracle </category>
          
      </categories>
      
      
        <tags>
            
            <tag> oracle </tag>
            
            <tag> rac </tag>
            
            <tag> crs </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
